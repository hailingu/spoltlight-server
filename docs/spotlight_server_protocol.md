# The data exchange protocol spotlight-server

Spotlight-server accepts a job flow expressed in json format. The job flow json must have 'name' field and 'backend' field. There is a simplest job flow json shown under below. A spotlight-server job constructed by operators defined in the splotlight-server.

    {
        "flow": {
            "name": "simplest_flow",
            "id": "spotlight-flow-1452433232-223-0",
            "backend": "spark",
            "schedule": "azkaban",
            "local": True,
            "operators": []
        }
    }

This is a simplest job flow. It has no operator. The 'id' field is generated by the splotlight-server, you do not assign it in json. Let's have a little more complicated example.

    {
        "flow": {
            "name": "spotlight_flow",
            "id": "",
            "backend": "scikitlearn",
            "schedule": "default",
            "local": "True",
            "running-mode": 'script',
            "operators": [
                {
                    "name": "IrisMultiClassData",
                    "op-index": "job0",
                    "op-running-id": "",
                    "op-category": "data-import",
                    "op-name": "import-csv",
                    "params": {
                        "input-path": "datasets/sample/iris_duplicated.txt"
                    },
                    "deps": []
                },
                {
                    "name": "RemoveDuplicatedRows",
                    "op-running-id": "",
                    "op-index": "job1",
                    "op-category": "data-transformation",
                    "op-name": "remove-duplicated-rows",
                    "params": {
                        "columns": "'ID SepalLength SepalWidth PetalLength PetalWidth Species'"
                    },
                    "deps": [
                        {
                            "op-index": "job0",
                            "op-out-index": 0
                        }
                    ]
                },
                {
                    "name": "DataSplit",
                    "op-index": "job2",
                    "op-category": "sample",
                    "op-name": "data-split",
                    "op-running-id": "",
                    "params": {
                        "percentage": 0.7
                    },
                    "deps": [
                        {
                            "op-index": "job1",
                            "op-out-index": 0
                        }
                    ]
                },
                {
                    "name": "Train",
                    "op-index": "job3",
                    "op-category": "machine-learning",
                    "op-name": "train",
                    "op-running-id": "",
                    "params": {
                        "label_column": "Species",
                        "train_columns": "'SepalLength SepalWidth PetalLength PetalWidth Species'"
                    },
                    "deps": [
                        {
                            "op-index": "job4",
                            "op-out-index": 0
                        },
                        {
                            "op-index": "job2",
                            "op-out-index": 0
                        }
                    ]
                },
                {
                    "name": "RandomForest",
                    "op-index": "job4",
                    "op-category": "machine-learning",
                    "op-name": "random-forest",
                    "op-running-id": "",
                    "params": {},
                    "deps": []
                }
            ]
        }
    }

It's a little complicated. There are 5 operators in operators fileds. Every operator in spotlight-server has 4 essential fields: 'op-index', 'op-category', 'op-name' and 'op-running-id', the job flow should specifiy 'op-index', 'op-category' and 'op-name' while 'op-running-id' is assigned by splotlight-server.

There is a json sample below which can be used in postman to post info to spotlight server.

    {
        "flow": {
            "name": "simplest_flow",
            "id": "",
            "backend": "spark",
            "operators": [
                {
                    "name": "IrisMultiClassData",
                    "op-index": "job0",
                    "rid": "",
                    "op-category": "data-import",
                    "op-name": "import-csv",
                    "local": "True",
                    "params": {
                        "input-path": " /home/hailingu/Git/spotlight-server/datasets/sample/iris_duplicated.txt",
                        "delimiter": ","
                    },
                    "deps": []
                }
            ]
        }
    }